# 基于修复器的图像质量指标调研
通过基于扩散模型的图像优化模块来进行数据增强，提升自定义场景数据质量，修复消除场景重建伪影以达到增强训练数据。现对文献中相关图像质量指标表现进行总结分析。

相关文献包括[StreetCrafter](https://arxiv.org/abs/2412.13188)、
[DIFIX3D+](https://arxiv.org/pdf/2503.01774?)、
[ReconDreamer](https://arxiv.org/pdf/2411.19548)、
[DriveDreamer4D](https://arxiv.org/pdf/2410.13571)

## 1. 各文献数据集整理
> a. [StreetCrafter](https://arxiv.org/abs/2412.13188)：Waymo-单个相机；   
> b. [DIFIX3D+](https://arxiv.org/pdf/2503.01774?)：DL3DV/RDS-单个相机；   
> c. [ReconDreamer](https://arxiv.org/pdf/2411.19548)：Waymo-单个相机；   
> d. [DriveDreamer4D](https://arxiv.org/pdf/2410.13571): Waymo-单个相机；

## 2. 指标分析总结
### 2.1 PSNR,SSIM,LPIPS
**PSNR.** The Peak Signal-to-Noise Ratio (PSNR) is widely used to measure the quality of reconstructed images by
comparing them to ground truth images. It is defined as:

$$
PSNR = 10 \cdot log_{10}\left(\frac{MAX^2}{MSE}\right),
$$

where MAX represents the maximum possible pixel value(e.g., 255 for 8-bit images), and MSE is the mean squared
error between the predicted image $I_{pred}$ and the ground truth image $I_{gt}$. Higher PSNR values indicate better reconstruction quality.

**SSIM.** The Structural Similarity Index (SSIM) evaluates the perceptual similarity between two images by considering
luminance, contrast, and structure. It is computed as:

$$
SSIM(I_{pred}, I_{gt}) = \frac{(2\mu_{pred}\mu_{gt} + C_1)(2\sigma_{pred,gt} + C_2)}{(\mu^2_{pred} + \mu^2_{gt} + C_1)(\sigma^2_{pred} + \sigma^2_{gt} + C_2)},
$$

where $\mu$ and $\sigma^2$ represent the mean and variance of the pixel intensities, respectively, and $\sigma_{pred,gt}$ is the covariance. The
constants $C_1$ and $C_2$ stabilize the division to avoid numerical instability.

**LPIPS.** The Learned Perceptual Image Patch Similarity(LPIPS) metric evaluates the perceptual similarity between two images based on 
feature embeddings extracted from pre-trained neural networks. It is defined as:

$$
LPIPS(I_{pred}, I_{gt}) = \sum_l \|\phi_l(I_{pred}) − \phi_l(I_{gt})\|_2^2,
$$

where $\phi_l$ represents the feature maps from the l-th layer of a pre-trained VGG-16 network. Lower LPIPS values indicate greater perceptual similarity.
